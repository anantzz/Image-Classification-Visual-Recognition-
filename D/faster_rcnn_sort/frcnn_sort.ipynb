{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pl346_YPjcxU"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import FasterRCNN\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dv1s1nRRsl_V"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained ResNet50 backbone\n",
        "backbone = resnet_fpn_backbone('resnet50', pretrained=True)\n",
        "\n",
        "num_classes = 91\n",
        "\n",
        "# Create the Faster R-CNN model with ResNet50 backbone\n",
        "model = FasterRCNN(backbone=backbone, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wWqeiIpv5mB6"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "T8Unq0md_xSS"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mXeQRaUe-kFh"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "def predict(image, model, device, detection_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Predict the output of an image after forward pass through\n",
        "    the model and return the bounding boxes, class names, and \n",
        "    class labels. \n",
        "    \"\"\"\n",
        "    # Transform the image to tensor.\n",
        "    image = transform(image).to(device)\n",
        "    # Add a batch dimension.\n",
        "    image = image.unsqueeze(0) \n",
        "    \n",
        "    # Get the predictions on the image.\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image) \n",
        "    # Get score for all the predicted objects.\n",
        "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
        "    # Get all the predicted bounding boxes.\n",
        "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
        "    # Get boxes above the threshold score.\n",
        "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
        "    pred_scores=pred_scores[pred_scores >= detection_threshold].astype(np.int32)\n",
        "    labels = outputs[0]['labels'][:len(boxes)]\n",
        "    # Get all the predicited class names.\n",
        "    # print(labels.cpu().numpy())\n",
        "    pred_classes = [classes[i] for i in labels.cpu().numpy()]\n",
        "    return boxes, pred_scores, pred_classes, labels\n",
        "    # return outputs\n",
        "\n",
        "\n",
        "def draw_boxes(boxes, classes, labels, image):\n",
        "    \"\"\"\n",
        "    Draws the bounding box around a detected object.\n",
        "    \"\"\"\n",
        "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
        "    tf = max(lw - 1, 1) # Font thickness.\n",
        "    for i, box in enumerate(boxes):\n",
        "        # print(box)\n",
        "        color = COLORS[labels[i]]\n",
        "        cv2.rectangle(\n",
        "            img=image,\n",
        "            pt1=(int(box[0]), int(box[1])),\n",
        "            pt2=(int(box[2]), int(box[3])),\n",
        "            color=color[::-1], \n",
        "            thickness=lw\n",
        "        )\n",
        "        cv2.putText(\n",
        "            img=image, \n",
        "            text=classes[i], \n",
        "            org=(int(box[0]), int(box[1]-5)),\n",
        "            fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
        "            fontScale=lw / 3, \n",
        "            color=color[::-1], \n",
        "            thickness=tf, \n",
        "            lineType=cv2.LINE_AA\n",
        "        )\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z4qQPDRQAY1a"
      },
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hswSYxFa_o63"
      },
      "outputs": [],
      "source": [
        "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n",
        "    \"\"\"Suppress overlapping detections.\n",
        "    Original code from [1]_ has been adapted to include confidence score.\n",
        "    .. [1] http://www.pyimagesearch.com/2015/02/16/\n",
        "           faster-non-maximum-suppression-python/\n",
        "    Examples\n",
        "    --------\n",
        "        >>> boxes = [d.roi for d in detections]\n",
        "        >>> scores = [d.confidence for d in detections]\n",
        "        >>> indices = non_max_suppression(boxes, max_bbox_overlap, scores)\n",
        "        >>> detections = [detections[i] for i in indices]\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes : ndarray\n",
        "        Array of ROIs (x, y, width, height).\n",
        "    max_bbox_overlap : float\n",
        "        ROIs that overlap more than this values are suppressed.\n",
        "    scores : Optional[array_like]\n",
        "        Detector confidence score.\n",
        "    Returns\n",
        "    -------\n",
        "    List[int]\n",
        "        Returns indices of detections that have survived non-maxima suppression.\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    boxes = boxes.astype(np.float)\n",
        "    pick = []\n",
        "\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2] #+ boxes[:, 0]\n",
        "    y2 = boxes[:, 3] #+ boxes[:, 1]\n",
        "\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    if scores is not None:\n",
        "        idxs = np.argsort(scores)\n",
        "    else:\n",
        "        idxs = np.argsort(y2)\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        idxs = np.delete(\n",
        "            idxs, np.concatenate(\n",
        "                ([last], np.where(overlap > max_bbox_overlap)[0])))\n",
        "\n",
        "    return pick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wHYVZ4DsAx3S"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "# image = Image.open(\"/content/car_new.jpeg\").convert('RGB')\n",
        "# # Create a BGR copy of the image for annotation.\n",
        "# image_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "# # Detect outputs.\n",
        "# with torch.no_grad():\n",
        "#     boxes, scores, classes_, labels = predict(image, model, device)\n",
        "# # Draw bounding boxes.\n",
        "# # print(boxes)\n",
        "# image = draw_boxes(boxes, classes_, labels, image_bgr)\n",
        "# # save_name = f\"{args['input'].split('/')[-1].split('.')[0]}_t{''.join(str(args['threshold']).split('.'))}_{args['model']}\"\n",
        "# # cv2.imshow('Image', image)\n",
        "# cv2.imwrite(\"detection.jpg\", image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ9LCEHOICIg",
        "outputId": "9628bb1b-d39d-4a02-ac6b-ac50e582115e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: filterpy in c:\\python310\\lib\\site-packages (1.4.5)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from filterpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\python310\\lib\\site-packages (from filterpy) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in c:\\python310\\lib\\site-packages (from filterpy) (3.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (4.37.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (9.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python310\\lib\\site-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install filterpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyRnsdmMD2Yj",
        "outputId": "03101264-f704-4e0e-d17b-9fec0e40ae4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "def cv2_imshow(image):\n",
        "    cv2.imshow('Image', image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "# from utils import *\n",
        "from sort_frcnn import *\n",
        "tracker=Sort()\n",
        "vid = cv2.VideoCapture(\"/content/video1.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, vid.get(cv2.CAP_PROP_FPS),(int(vid.get(3)),int(vid.get(4))))\n",
        "uniqueCars={}\n",
        "while(True):\n",
        "    ret, frame_bgr = vid.read()\n",
        "    if(ret==False):\n",
        "      break\n",
        "    frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame)\n",
        "    with torch.no_grad():\n",
        "        boxes, scores, classes_, labels = predict(pilimg, model, device)\n",
        "    \n",
        "    detections=np.concatenate([boxes,scores.reshape(-1,1)],axis=1)\n",
        "    indices = non_max_suppression(boxes, 0.4, scores)\n",
        "    detections = transform(np.array([detections[i] for i in indices]))[0].to(device)\n",
        "    classes_=np.array([classes_[i] for i in indices])\n",
        "    labels=np.array([labels.cpu().numpy()[i] for i in indices])\n",
        "    \n",
        "    tracked_objects = tracker.update(detections.cpu())\n",
        "    for i,t in enumerate(tracked_objects):\n",
        "      x1,y1,x2,y2,id=t\n",
        "      if(classes_[i]==\"car\"):\n",
        "        uniqueCars[id]=\"car\"\n",
        "        bx=np.array([x1,y1,x2,y2]).reshape(1,-1)\n",
        "        frame_bgr = draw_boxes(bx, np.array([\"car-\"+str(int(id))]),np.array([int(labels[i])]), frame_bgr)\n",
        "    clear_output(wait=True)\n",
        "    out.write(frame_bgr)\n",
        "print(len(uniqueCars))\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
