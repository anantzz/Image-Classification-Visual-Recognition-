{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/vr_3d.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3MNxTFbAoBL",
        "outputId": "d6942f67-4df3-47af-e16e-5086b5e0bdcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/vr_3d.zip\n",
            "replace config/coco.data? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7-FXS4RR8YPJ"
      },
      "outputs": [],
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "\n",
        "import os, sys, time, datetime, random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 0744 /content/config/download_weights.sh\n",
        "!/content/config/download_weights.sh"
      ],
      "metadata": {
        "id": "4qdNlf6oAAGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bddc15d-2269-4f3f-829a-a687aca34c52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 11:26:11--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.5’\n",
            "\n",
            "yolov3.weights.5    100%[===================>] 236.52M  11.9MB/s    in 25s     \n",
            "\n",
            "2023-03-22 11:26:37 (9.32 MB/s) - ‘yolov3.weights.5’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LQ44cVs48YPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3455bb9-7cbe-4aa3-97f1-b0a970ae2110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "config_path='config/yolov3.cfg'\n",
        "weights_path='yolov3.weights'\n",
        "class_path='config/coco.names'\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4\n",
        "\n",
        "# Load model and weights\n",
        "model = Darknet(config_path, img_size=img_size)\n",
        "model.load_weights(weights_path)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "classes = utils.load_classes(class_path)\n",
        "Tensor = torch.cuda.FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ugWUbRs8YPL"
      },
      "outputs": [],
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms = transforms.Compose([ transforms.Resize((imh, imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), max(int((imw-imh)/2),0), max(int((imh-imw)/2),0), max(int((imw-imh)/2),0)),\n",
        "                        (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.non_max_suppression(detections, 80, conf_thres, nms_thres)\n",
        "    return detections[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-VFVSsQ3PR8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jg9ESkm88YPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96316776-329d-443f-ff6d-f06c30165b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['random']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.9/dist-packages (1.4.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from filterpy) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from filterpy) (1.22.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (4.39.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->filterpy) (1.0.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->filterpy) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/sort.py:33: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"iou\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at /content/sort.py (38)\n",
            "\n",
            "File \"sort.py\", line 38:\n",
            "def iou(bb_test,bb_gt):\n",
            "    <source elided>\n",
            "  \"\"\"\n",
            "  xx1 = np.maximum(bb_test[0], bb_gt[0])\n",
            "  ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"iou\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"sort.py\", line 34:\n",
            "@jit\n",
            "def iou(bb_test,bb_gt):\n",
            "^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"sort.py\", line 34:\n",
            "@jit\n",
            "def iou(bb_test,bb_gt):\n",
            "^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "videopath = 'video3.mp4'\n",
        "\n",
        "%pylab inline \n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "# initialize Sort object and video capture\n",
        "!pip install filterpy\n",
        "from sort import *\n",
        "vid = cv2.VideoCapture(videopath)\n",
        "mot_tracker = Sort() \n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output3.mp4', fourcc, vid.get(cv2.CAP_PROP_FPS),(int(vid.get(3)),int(vid.get(4))))\n",
        "uniqueCars={}\n",
        "\n",
        "while(True):\n",
        "#for ii in range(40):\n",
        "    ret, frame = vid.read()\n",
        "    if(ret==False):\n",
        "      break\n",
        "    frame_new = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame_new)\n",
        "    detections = detect_image(pilimg)\n",
        "    # print(detections.shape)\n",
        "    img = np.array(pilimg)\n",
        "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "    unpad_h = img_size - pad_y\n",
        "    unpad_w = img_size - pad_x\n",
        "    if detections is not None:\n",
        "        tracked_objects = mot_tracker.update(detections.cpu())\n",
        "\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "        n_cls_preds = len(unique_labels)\n",
        "        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
        "            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
        "            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
        "            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
        "            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
        "\n",
        "            color = colors[int(obj_id) % len(colors)]\n",
        "            color = [i * 255 for i in color]\n",
        "            cls = classes[int(cls_pred)]\n",
        "            if(cls==\"car\"):\n",
        "              uniqueCars[str(int(obj_id))]=\"car\"\n",
        "              cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
        "              cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60, y1), color, -1)\n",
        "              cv2.putText(frame, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
        "\n",
        "    # fig=plt.figure(figsize=(12, 8))\n",
        "    # plt.title(\"Video Stream\")\n",
        "    # plt.imshow(frame)\n",
        "    # plt.show()\n",
        "    # clear_output(wait=True)\n",
        "    out.write(frame)\n",
        "print(len(uniqueCars))\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PAuSKAna8YPM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}