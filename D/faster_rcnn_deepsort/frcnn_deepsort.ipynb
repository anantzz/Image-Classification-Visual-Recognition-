{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl346_YPjcxU"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import FasterRCNN\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')"
      ],
      "metadata": {
        "id": "dv1s1nRRsl_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "wWqeiIpv5mB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "metadata": {
        "id": "T8Unq0md_xSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "def predict(image, model, device, detection_threshold=0.8):\n",
        "    \"\"\"\n",
        "    Predict the output of an image after forward pass through\n",
        "    the model and return the bounding boxes, class names, and \n",
        "    class labels. \n",
        "    \"\"\"\n",
        "    # Transform the image to tensor.\n",
        "    image = transform(image).to(device)\n",
        "    # Add a batch dimension.\n",
        "    image = image.unsqueeze(0) \n",
        "    # image = Variable(image)\n",
        "    # Get the predictions on the image.\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image) \n",
        "    # Get score for all the predicted objects.\n",
        "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
        "    # Get all the predicted bounding boxes.\n",
        "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
        "    # Get boxes above the threshold score.\n",
        "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
        "    pred_scores=pred_scores[pred_scores >= detection_threshold].astype(np.int32)\n",
        "    labels = outputs[0]['labels'][:len(boxes)]\n",
        "    # Get all the predicited class names.\n",
        "    # print(labels.cpu().numpy())\n",
        "    pred_classes = [classes[i] for i in labels.cpu().numpy()]\n",
        "    return boxes, pred_scores, pred_classes, labels\n",
        "    # return outputs\n",
        "\n",
        "\n",
        "def draw_boxes(boxes, classes, labels, image):\n",
        "    \"\"\"\n",
        "    Draws the bounding box around a detected object.\n",
        "    \"\"\"\n",
        "    lw = max(round(sum(image.shape) / 2 * 0.003), 2)  # Line width.\n",
        "    tf = max(lw - 1, 1) # Font thickness.\n",
        "    for i, box in enumerate(boxes):\n",
        "        # print(box)\n",
        "        color = COLORS[labels[i]]\n",
        "        cv2.rectangle(\n",
        "            img=image,\n",
        "            pt1=(int(box[0]), int(box[1])),\n",
        "            pt2=(int(box[2]), int(box[3])),\n",
        "            color=color[::-1], \n",
        "            thickness=lw\n",
        "        )\n",
        "        cv2.putText(\n",
        "            img=image, \n",
        "            text=classes[i], \n",
        "            org=(int(box[0]), int(box[1]-5)),\n",
        "            fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
        "            fontScale=lw / 3, \n",
        "            color=color[::-1], \n",
        "            thickness=tf, \n",
        "            lineType=cv2.LINE_AA\n",
        "        )\n",
        "    return image"
      ],
      "metadata": {
        "id": "mXeQRaUe-kFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.eval().to(device)"
      ],
      "metadata": {
        "id": "z4qQPDRQAY1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n",
        "    \"\"\"Suppress overlapping detections.\n",
        "    Original code from [1]_ has been adapted to include confidence score.\n",
        "    .. [1] http://www.pyimagesearch.com/2015/02/16/\n",
        "           faster-non-maximum-suppression-python/\n",
        "    Examples\n",
        "    --------\n",
        "        >>> boxes = [d.roi for d in detections]\n",
        "        >>> scores = [d.confidence for d in detections]\n",
        "        >>> indices = non_max_suppression(boxes, max_bbox_overlap, scores)\n",
        "        >>> detections = [detections[i] for i in indices]\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes : ndarray\n",
        "        Array of ROIs (x, y, width, height).\n",
        "    max_bbox_overlap : float\n",
        "        ROIs that overlap more than this values are suppressed.\n",
        "    scores : Optional[array_like]\n",
        "        Detector confidence score.\n",
        "    Returns\n",
        "    -------\n",
        "    List[int]\n",
        "        Returns indices of detections that have survived non-maxima suppression.\n",
        "    \"\"\"\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    boxes = boxes.astype(np.float)\n",
        "    pick = []\n",
        "\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2] + boxes[:, 0]\n",
        "    y2 = boxes[:, 3] + boxes[:, 1]\n",
        "\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    if scores is not None:\n",
        "        idxs = np.argsort(scores)\n",
        "    else:\n",
        "        idxs = np.argsort(y2)\n",
        "\n",
        "    while len(idxs) > 0:\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        idxs = np.delete(\n",
        "            idxs, np.concatenate(\n",
        "                ([last], np.where(overlap > max_bbox_overlap)[0])))\n",
        "\n",
        "    return pick"
      ],
      "metadata": {
        "id": "hswSYxFa_o63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# image = Image.open(\"/content/car_new.jpeg\").convert('RGB')\n",
        "# # Create a BGR copy of the image for annotation.\n",
        "# image_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "# # Detect outputs.\n",
        "# with torch.no_grad():\n",
        "#     boxes, scores, classes_, labels = predict(image, model, device)\n",
        "# # Draw bounding boxes.\n",
        "# # print(boxes)\n",
        "# image = draw_boxes(boxes, classes_, labels, image_bgr)\n",
        "# # save_name = f\"{args['input'].split('/')[-1].split('.')[0]}_t{''.join(str(args['threshold']).split('.'))}_{args['model']}\"\n",
        "# # cv2.imshow('Image', image)\n",
        "# cv2.imwrite(\"detection.jpg\", image)\n"
      ],
      "metadata": {
        "id": "wHYVZ4DsAx3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def box_tlbr_to_tlwh(boxes):\n",
        "  '''\n",
        "  boxes: ndarray of all boxes\n",
        "  return boxes in tlwh format\n",
        "  '''\n",
        "  for b in boxes:\n",
        "    b[2]=b[2]-b[0]\n",
        "    b[3]=b[3]-b[1]\n",
        "  return boxes"
      ],
      "metadata": {
        "id": "wJ9LCEHOICIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "# from utils import *\n",
        "from deep_sort import tools, detection, nn_matching, tracker\n",
        "\n",
        "tracker=tracker.Tracker(nn_matching.NearestNeighborDistanceMetric(\"euclidean\",0.5))\n",
        "vid = cv2.VideoCapture(\"/content/traffic1.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, vid.get(cv2.CAP_PROP_FPS),(int(vid.get(3)),int(vid.get(4))))\n",
        "uniqueCars={}\n",
        "while(True):\n",
        "    # print(\"hi\")\n",
        "    ret, frame_bgr = vid.read()\n",
        "    if(ret==False):\n",
        "      break\n",
        "    frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame)\n",
        "    with torch.no_grad():\n",
        "        boxes, scores, classes_, labels = predict(pilimg, model, device)\n",
        "    boxes=box_tlbr_to_tlwh(boxes)\n",
        "    encoder=tools.create_box_encoder(\"deep_sort/mars-small128.pb\")\n",
        "    fts=encoder(frame_bgr,boxes)\n",
        "    detections=[detection.Detection(boxes[i],scores[i],fts[i],classes_[i]) for i in range(len(boxes))]\n",
        "    \n",
        "    indices = non_max_suppression(boxes, 0.4, scores)\n",
        "    \n",
        "    detections = [detections[i] for i in indices]\n",
        "    \n",
        "    labels=np.array([labels.cpu().numpy()[i] for i in indices])\n",
        "    \n",
        "    tracker.predict()\n",
        "    tracker.update(detections)\n",
        "    tracked_objects=tracker.tracks\n",
        "    for i,t in enumerate(tracked_objects):\n",
        "      if(t.cls==\"car\"):\n",
        "        uniqueCars[t.track_id]=\"car\"\n",
        "        bx=t.to_tlbr()\n",
        "        frame_bgr = draw_boxes(bx, np.array([\"car-\"+str(int(t.track_id))]),np.array([3]), frame_bgr)\n",
        "    clear_output(wait=True)\n",
        "    out.write(frame_bgr)\n",
        "print(len(uniqueCars))\n",
        "out.release()"
      ],
      "metadata": {
        "id": "eyRnsdmMD2Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJAsNHytd6TQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}